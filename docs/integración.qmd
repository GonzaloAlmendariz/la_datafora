---
execute:
  warning: false
  message: false
---

# Integración

¿Cómo podemos usar R para analizar datos? En este capítulo, exploraremos los conceptos fundamentales que forman la base del análisis de datos en R, con un enfoque práctico en herramientas y procesos esenciales. Nuestro objetivo este capítulo será explicar la **importancia del manejo de datos** y cómo trabajar de manera eficiente con **`data.frames`** y **`tibbles`**.

A lo largo del capítulo, nos centraremos en varios aspectos clave que forman parte del flujo de trabajo en el análisis de datos utilizando herramientas del tidyverse:

-   **La importación de datos**: Aprenderemos a cargar datos desde diferentes fuentes, como archivos CSV o Excel, utilizando paquetes especializados.

-   **La limpieza de datos**, donde aprenderemos a manejar problemas comunes como nombres de columnas inconsistentes, valores perdidos y duplicados, y cómo corregir tipos de datos incorrectos.

-   **Las funciones resumen**, que nos permiten explorar rápidamente nuestros datos, identificar patrones y obtener información sobre su estructura y contenido.

-   **La manipulación de datos con dplyr**, donde descubriremos cómo filtrar, seleccionar, agrupar y transformar datos con funciones diseñadas para ser intuitivas y fáciles de combinar.

-   **La creación de visualizaciones con ggplot2**, donde aprenderemos a generar gráficos apropiados que no solo nos ayuden a explorar nuestros datos, sino que también comunican hallazgos de manera visual.

Este capítulo es extenso, ya que cubre una amplia gama de conceptos fundamentales que se usarán a lo largo del resto del libro. Sin embargo, cada sección está diseñada para ser progresiva, conectando cada paso con el siguiente. Te animo a avanzar paso a paso, ya que cada etapa es fundamental es clave para poder entender el resto del contenido teórico del libro.

## Data.frames

Cuando recolectamos o hacemos uso de conjuntos de datos, estos suelen estar almacenados en **estructuras tabulares**, lo que facilita su comprensión y análisis. Una **estructura tabular** se refiere a una organización de los datos donde cada columna representa una **variable** (es decir, una característica o atributo que estamos observando), y cada fila corresponde a una **observación** (un registro individual de los datos, como un caso o instancia). En R, la forma más común de trabajar con este tipo de estructuras es a través de **objetos denominados** `data.frames`.

![Elaboración propia](images/Observación-01.png)

Recuerda que, en el capítulo anterior, cuando exploramos los tipos de objetos en R, vimos que, a diferencia de una matriz (que también tiene una forma tabular pero almacena datos de un solo tipo), un `data.frame` permite que cada columna contenga datos de diferentes tipos. Esto significa que podemos trabajar simultáneamente con variables numéricas, categóricas o lógicas dentro de una misma estructura.

Imaginemos que queremos crear un conjunto de datos con tres variables:\
- **Edad**: numérica, que representa la edad de los encuestados.\
- **Género**: categórica, con valores como "Masculino" y "Femenino".\
- **Medio de comunicación preferido**: categórica, con valores como "Televisión", "Radio", "Internet" y "Prensa Escrita".

Podemos construir este `data.frame` en R utilizando vectores para cada variable y luego combinándolos:

```{r}
# Crea vectores para cada variable
edad = c(25, 30, 35, 40, 28)
genero = c("Femenino", "Masculino", "Femenino", 
           "Masculino", "Femenino")
medio_comunicacion = c("Internet", "Televisión", "Radio", 
                        "Prensa Escrita", "Internet")

# Combina los vectores en un data.frame
encuesta = data.frame(Edad = edad, 
                       Género = genero, 
                       Medio_de_comunicación_preferido = medio_comunicacion)
```

El resultado es una tabla que muestra la edad, el género y medio de comunicación preferidos de los encuestados, estructurados en filas y columnas.

```{r}
encuesta
```

Además, peudes seleccionar una columna de `data.frame` de forma individual utilizando el signo `$`

```{r}
encuesta$Medio_de_comunicación_preferido
```

Para observar el data.frame de manera visual, RStudio ofrece herramientas muy convenientes. Podemos localizar el nombre del **data.frame** en el panel "Entorno" (Environment) y hacer clic en el ícono de la tabla que aparece al lado. Esto abrirá una vista interactiva en forma de hoja de cálculo, donde podrás explorar las filas y columnas de tu conjunto de datos.

![](images/Observación-6.png)

Otra forma, desde la consola, es usar la función `View()`. Por ejemplo, si tu **data.frame** se llama `encuesta`, simplemente escribe el siguiente código en la consola:

```{r}
# View(encuesta)
```

Aunque esta es una forma de generar un **data.frame**, es importante mencionar que, en la práctica, la mayoría de los conjuntos de datos no se crean desde cero. Normalmente, los datos provienen de otras fuentes, como archivos de texto, hojas de cálculo o bases de datos. Por ello, uno de los pasos más importantes al trabajar con datos es **importarlos desde estas fuentes**, lo cual veremos en más detalle más adelante.

## El flujo de trabajo en el Tidyverse

Como vimos en el anterior capítulo, un paquete en R es una colección de funciones y datos que extienden las capacidades básicas del lenguaje. Los paquetes te permiten realizar tareas específicas de manera más eficiente. Al instalar y cargar un paquete, se accede a un conjunto de herramientas especializadas que simplifican tu trabajo.

Debido a que existe una multitud enorme de paquetes, sugiero les eches un vistazo siempre que puedas. Debido al propósito de este libro, nos centraremos especialmente en uno de estos que, a nivel personal, es muy intuitivo y poderoso: **El Tidyverse**. [@tidyverse-2]

El tidyverse es un sistema coherente de paquetes para la manipulación, exploración y visualización de datos que comparten una lógica de diseño común. Estos paquetes son fundamentales en el flujo de trabajo de un analista de datos y, en mi opinión personal, son algunos de los más comprensibles e intuitivos que existen en el mundo de la programación.

Algunas características del tidyverse:

-   Todos los paquetes del tidyverse siguen principios de diseño similares y se entienden entre sí.

-   La sintaxis y las funciones están diseñadas para ser fáciles de entender y usar.

[![Extraído de teachdatascience.com](images/clipboard-3030342419.png){width="560"}](https://teachdatascience.com/)

La imagen ilustra el flujo de trabajo típico al analizar datos usando los paquetes del **tidyverse**. Recuerda que debemos seguir un orden, pues esto asegura que podamos manejar nuestros datos de manera **coherente**, **reproducible** y **eficiente**.

El flujo de trabajo incluye las siguientes etapas principales:

## Importación y resumen

El primer paso en el flujo de trabajo es **importar los datos desde fuentes externas** al entorno de R. En las ciencias sociales, los investigadores suelen trabajar con bases de datos provenientes de encuestas, experimentos o datos recolectados en plataformas como hojas de cálculo de Excel, herramientas de encuestas en línea o programas de análisis estadístico como SPSS o Stata. Aunque R incluye funciones base (viene por defecto y no necesitan cargar algún paquete) para la importación de datos, como `read.csv()`, en este capítulo nos enfocaremos en los paquetes especializados como **`readr`**, **`readxl`** y **`haven`**, que son más actuales y generan **`tibbles`**, una versión mejorada de los `data.frames`.

Un ejemplo interesante es el caso de la **Encuesta Nacional de Hogares (Enaho)**, cuyos datos son publicados por las instituciones encargadas en diferentes formatos: **CSV**, **Stata (.dta)** y **SPSS (.sav)**. Esto demuestra cómo una misma base de datos puede estar disponible en múltiples formatos para adaptarse a las herramientas utilizadas por distintos analistas. Por ejemplo, un investigador que utiliza Excel podría optar por trabajar con el formato CSV, mientras que alguien que trabaja con Stata o SPSS puede preferir los archivos nativos de esos programas.

### Importación

Los archivos que utilizaremos a lo largo de este libro están disponibles en la **carpeta de archivos del libro**, la cual se recomienda descargar y guardar en una **carpeta de trabajo** en tu computadora. Para seguir los ejemplos en este capítulo, asegúrate de tener los archivos en tu carpeta de trabajo y configurar tu directorio de trabajo en RStudio.

El formato **CSV** (Comma-Separated Values) es uno de los más utilizados debido a su simplicidad y compatibilidad. Cada fila en un archivo CSV representa una observación, y los valores dentro de cada fila están separados por comas.

Un ejemplo de cómo podría lucir un archivo CSV:

```         
ID,Edad,Género,Ingreso
1,25,Femenino,1500
2,30,Masculino,2000
3,45,Femenino,2500
```

El paquete **`readr`** es parte del tidyverse y está diseñado para leer archivos CSV.

```{r}
# Cargamos el paquete readr
library(readr)
```

Al importar un conjunto de datos debemos nombrarlo.

```{r}
# Importamos el archivo CSV y lo asignamos a un objeto
encuesta_csv = read_csv("encuesta.csv")

# Mostramos
encuesta_csv
```

Los archivos de Excel son comunes en las ciencias sociales debido a su facilidad de uso y capacidad para almacenar datos tabulares en varias hojas. El paquete **`readxl`** [@readxl] permite importar estos archivos, ya sea en formato `.xls` o `.xlsx`, sin necesidad de tener Excel instalado.

```{r}
# Cargamos el paquete readxl
library(readxl)
```

```{r}
# Importamos los datos desde un archivo Excel
encuesta_excel = read_excel("encuesta.xlsx")

# Mostramos 
encuesta_excel
```

Si el archivo contiene múltiples hojas, podemos especificar cuál importar utilizando el argumento `sheet`:

```{r}
# Importamos una hoja específica del archivo Excel
# encuesta_excel_hoja = read_excel("encuesta.xlsx", 
#                                  sheet = "Resultados")
```

En ciencias sociales es común trabajar con datos provenientes de software estadístico como Stata o SPSS. Estos formatos incluyen información adicional, como etiquetas de variables, que son importantes para interpretar los datos correctamente. Para trabajar con estos archivos en R, utilizamos el paquete **`haven`** [@haven].

```{r}
# Cargamos el paquete haven
library(haven)
```

Importamos un archivo Stata y lo asignamos a un objeto

```{r}
encuesta_stata = read_dta("encuesta.dta")

# Mostramos 
encuesta_stata
```

O un archivo SPSS

```{r}
encuesta_spss = read_sav("encuesta.sav")

# Mostramos
encuesta_spss
```

### Funciones resumen

Una vez que hemos importado los datos a R, es fundamental conocer su estructura y contenido antes de proceder con el análisis. Para ello, podemos utilizar una variedad de **funciones resumen** que nos permiten explorar el tibble y obtener información importante sobre las variables y los datos contenidos allí.

**`str()`** es una función base que describe la estructura del objeto, incluyendo el número de observaciones, las variables y sus tipos. Es muy parecida a `glimpse()` con la diferencia que es una función base y por lo tanto no depende del ecosistema tidyverse.

```{r}
# Información estructural básica del tibble
str(encuesta_csv)
```

**`glimpse()`** es una función del tidyverse que proporciona una vista compacta del tibble, mostrando los nombres de las variables, sus tipos de datos y una muestra de valores.

```{r}
# Cargamos el paquete tibble
library(tibble)
# Exploramos la estructura general del tibble
glimpse(encuesta_csv)
```

**`summary()`** proporciona estadísticas descriptivas básicas para cada columna, como mínimos, máximos, medias, medianas y conteos de valores para variables categóricas. De especial utilidad para el próximo capítulo.

```{r}
# Resumen estadístico de las variables
summary(encuesta_csv)
```

**`head()`** muestra las primeras filas del tibble, permitiendo observar una muestra inicial de los datos. Puedes indicar cuanto valores deseas que devuelva especificando el segundo argumento, por defecto son seis.

```{r}
# Visualizamos las primeras seis filas
head(encuesta_csv)
```

```{r}
# Visualizamos las primeras dos filas
head(encuesta_csv, 2)
```

**`tail()`** es similar a `head()`, pero muestra las últimas filas del tibble.

```{r}
# Visualizamos las últimas seis filas
tail(encuesta_csv)
```

```{r}
# Visualizamos las últimas dos filas
tail(encuesta_csv, 2)
```

**`dim()`** devuelve las dimensiones del tibble, es decir, el número total de filas y columnas.

```{r}
# Verificamos las dimensiones del tibble
dim(encuesta_csv)
```

**`colnames()`** muestra los nombres de las columnas (variables) del tibble

```{r}
# Consultamos los nombres de las columnas
colnames(encuesta_csv)
```

Perfecto, ya tenemos el primer paso cubierto. Manos a la obra.

## Limpieza

Una vez que hemos importado los datos, el siguiente paso es **limpiarlos**. Este proceso consiste en identificar y corregir problemas comunes como valores faltantes, nombres de columnas inconsistentes, duplicados y tipos de datos incorrectos. La limpieza asegura que los datos estén en un estado coherente y listo para ser transformado o analizado.

![Extraído de: https://www.teraflow.ai/3-big-benefits-of-data-cleansing/](images/clipboard-3973043610.png){width="455"}

**Manejo de valores faltantes**

El **manejo de valores faltantes** es uno de los aspectos más complejos en la limpieza de datos, y un tema importante a considerar al trabajar con conjuntos de datos. Un **valor perdido** o **NA** en R no es lo mismo que un **0** o un espacio vacío. Un valor perdido (o **NA**, que significa "Not Available") es una celda que no contiene información en absoluto, lo que puede ocurrir por diversas razones, como un error en la recolección de los datos, una respuesta no proporcionada en una encuesta o una omisión involuntaria al momento de ingresar los datos. Por ejemplo:

```{r}
encuesta_excel
```

En R, puedes detectar estos valores con funciones como `is.na()`, que devuelve un valor lógico (TRUE o FALSE) indicando si un valor es NA. Seleccionamos la columna.

```{r}
is.na(encuesta_excel$edad)
```

Recuerda que puedes sumar un vector lógico para contar los TRUE. En este caso los valores perdidos.

```{r}
# Cantidad de valores perdidos 
sum(is.na(encuesta_excel$edad)) 
```

Una de las formas más simples de manejar valores faltantes es eliminarlos por completo. Esto puede hacerse utilizando la función `drop_na()` del paquete **tidyr** [@tidyr], que elimina las filas que contienen al menos un valor NA en cualquier columna. Esta es una solución rápida, pero es importante ser cauteloso, ya que puede resultar en la pérdida de información valiosa si hay muchos datos faltantes.

```{r}
# Cargamos tidyr
library(tidyr)
```

```{r}
# Eliminamos filas con valores faltantes
drop_na(encuesta_excel)
```

Comparemos

```{r}
# Podemos nombrarlo
encuesta_sin_na = drop_na(encuesta_excel)

# Presta atención a las dimensiones del tibble original y del tibble sin NA
dim(encuesta_excel)
dim(encuesta_sin_na)
```

Si queremos ser más específicos y eliminar valores faltantes solo en una columna particular, podemos usar:

```{r}
# Eliminamos filas donde la columna 'edad' tiene NA
encuesta_sin_na = drop_na(encuesta_excel, edad)

encuesta_sin_na
```

Aunque eliminar valores faltantes puede ser un enfoque válido en algunos casos, no siempre es ideal. Si eliminamos demasiadas filas, podemos perder una cantidad significativa de información, lo que podría alterar los resultados de nuestro análisis. Por eso, en lugar de eliminar, muchas veces es preferible **imputar** los valores faltantes, es decir, reemplazarlos con un valor estimado. Por ejemplo, algunas estrategias comunes para imputar valores incluyen **reemplazar por el promedio** en el caso de variables numéricas o **reemplazar por la moda** en variables categóricas donde los valores faltantes pueden ser reemplazados por el valor más frecuente (la moda).

Para las siguentes técnicas de limpieza utilizaremos el conjunto de datos `encuesta_problematica`. Te animo a que puedas identificar que posible problemas tiene antes de seguir adelante.

```{r}
datos_problema = read.csv('encuesta_problematica.csv')

datos_problema
```

Si te diste cuenta, utilizamos **`read.csv`** en lugar de **`read_csv`** del paquete **readr**, ya que **`read_csv`** detecta automáticamente el tipo de dato de cada columna, incluso si hay errores en los valores. Para el propósito de este ejemplo, donde queremos ilustrar y solucionar errores comunes en los datos, no lo utilizaremos. ¡Pero ahí tienes otra gran razón para preferir **`read_csv`** en tu flujo de trabajo diario!

**Estandarización de nombres de columnas**

Los nombres de las columnas en los conjuntos de datos pueden ser inconsistentes, incluir caracteres especiales o espacios que dificulten el manejo en R.

Primero, identificamos los nombres originales del conjunto de datos utilizando la función base `names()`:

```{r}
colnames(datos_problema)
```

Para resolver esto, utilizamos la función **`clean_names()`** del paquete **janitor**. Esta función transforma automáticamente los nombres de las columnas en un formato limpio y consistente:

```{r}
# Cargar el paquete janitor
library(janitor)

# Estandarizar los nombres de las columnas
datos_problema = clean_names(datos_problema)
```

Mostramos

```{r}
colnames(datos_problema)
```

**Eliminación de duplicados**

En algunos casos, los datos pueden contener filas duplicadas que distorsionan el análisis. Podemos identificar y eliminar estas filas utilizando la función `distinct()` de `dplyr`.

```{r}
# Cargamos dplyr
library(dplyr)

# Eliminamos filas duplicadas
datos_problema = distinct(datos_problema)
```

Mostramos

```{r}
datos_problema
```

Para lo siguientes pasos vamos a utilizar como ejemplo el conjunto de datos **gapminder**. Este conjuto de datos contiene información sobre indicadores socioeconómicos de varios países a lo largo del tiempo. Incluye variables como la esperanza de vida (`lifeExp`), el PIB per cápita (`gdpPercap`) y la población a través de los años.

Puedes descargar el conjunto de datos de datos desde la Datáfora o en el siguiente enlace y guardarla en tu carpeta de trabajo: [gapminder.csv](https://github.com/kirenz/datasets/blob/master/gapminder.csv).

Dado que el archivo está en formato `.csv` (valores separados por comas), utilizaremos la función `read_csv()` del paquete `readr`, que forma parte del tidyverse, para leer los datos:

```{r}
library(readr)

# Importamos el archivo CSV
gapminder = read_csv('gapminder.csv')

# Mostramos las primeras filas del dataset
head(gapminder)
```

Otra opción es instalar y cargar el paquete llamado `gapminder` [@gapminder], que contiene el mismo conjunto de datos:

```{r}
# Cargar el paquete
library(gapminder)

# Mostramos las primeras filas del dataset
head(gapminder)
```

## Manipulación

Una vez limpios nuestros datos pasamos al tercer paso: la manipulación de datos. La manipulación de datos consiste en transformar y preparar los datos para su análisis, lo que puede incluir la creación de nuevas variables, el filtrado de observaciones o la omisión de alguna variable. Para ello, usaremos el paquete `dplyr` [@dplyr] del tidyverse.

`dplyr` es un paquete del tidyverse diseñado específicamente para la manipulación de datos. Proporciona un conjunto de funciones que permiten seleccionar, filtrar, ordenar, resumir y transformar datos en data.frames. Una de las características más importantes de dplyr es su uso del "pipe operator" (`%>%`), que permite encadenar múltiples operaciones de manera secuencial, pasando el resultado de una función directamente como entrada a la siguiente. Esto hace que el código sea más fácil de leer y mantener.

El atajo del teclado para el pipe operator (`%>%`) es:

-   Ctrl + Shift + M (Windows)

-   Cmd + Shift + M (Mac)

**Un sistema de tuberías**

Para poder realizar múltiples acciones en secuencia conectando cada acción con la siguiente a través de "tuberías" debemos utilizar lo que se llama el *pipe operator* (`%>%`).

![](images/clipboard-3784925606.png)

Lo iremos viendo, de momento tienes que conocer algunas de las principales funciones de dplyr:

-   `filter()`: Filtra filas de un dataframe según una condición específica.
-   `select()`: Selecciona columnas específicas de un dataframe.
-   `mutate()`: Crea nuevas columnas o modifica las existentes en un dataframe.
-   `summarize()`: Resumen estadístico de las columnas de un dataframe.
-   `arrange()`: Ordena las filas de un dataframe según una o más variables.
-   `group_by()`: Agrupa un dataframe por una o más variables, preparándolo para operaciones de resumen.

Para empezar a trabajar con `dplyr` recuerda primero cargarlo:

```{r}
#install.packages('dplyr')
```

```{r, warning=FALSE}
library(dplyr)
```

A continuación, verás que muchas de las funciones terminan con un comando `head()` , esto es únicamente para evitar mostrar todos los datos del data.frame por motivos puramente estéticos del libro.

### Funciones principales

**Filter()**

La función `filter()` nos ayuda a filtrar filas bajo una condición.

![Elaboración propia](images/clipboard-1638975480.png)

Utilizando el pipe operator (`%>%`) vamos a filtrar nuestros datos únicamente para aquellos que sean del 2007. Para ello nuestra condición sera que la variable `year` sea igual a 2007.

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>% 
  # Filtramos las filas donde la variable year sea igual a 2007
  filter(year == 2007) %>% 
  # Mostramos las primeras 5 filas del resultado para fines estéticos
  head(5)
```

Podemos asignarle un propio nombre

```{r}
gapminder_2007 = gapminder %>%
  filter(year == 2007)
```

Ahora tenemos otro `data.frame` filtrado solo por los valores que tenían como año el 2007. Podemos resumirlo de la misma forma.

```{r}
str(gapminder_2007)
```

También podemos filtrar con más de una condición. Imaginemos que queremos saber los valores del 2002 del Perú

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>% 
  # Filtramos las filas donde year sea igual a 2002
  filter(year == 2002, 
         # Y donde el país sea igual a 'Peru'
         country == 'Peru')
```

O los países que al año 2007 tenían mas de 100 millones de habitantes.

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>% 
  # Filtramos las filas donde year sea igual a 2007
  filter(year == 2007, 
         # Y donde la población (pop) sea mayor a 100 millones
         pop > 100000000)
```

**Select()**

Utilizamos la función `select()` para filtrar por las columnas que son de nuestro interés. Muchas veces vamos a querer seleccionar solo algunas para nuestro análisis.

![](images/clipboard-4017595068.png)

Como argumentos `select()` solo necesita el nombre de la columna de interés.

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>%
  # Seleccionamos solo las columnas country, year y pop
  select(country, year, pop) %>%
  head(5)

```

**Arrange()**

Utilizamos la función `arrange()` para poder ordenar las observaciones (filas) que tengamos.

![](images/clipboard-3710368930.png)

Imagina que queremos ordenarlo por quien tenga la menor esperanza de vida.

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>%
  # Ordenamos las filas por la columna lifeExp en orden ascendente
  arrange(lifeExp) %>%
  head(5)
```

Si lo queremos de mayor a menor solo debemos que envolverlo en otra función llamada `desc()`

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>%
  # Ordenamos las filas por la columna lifeExp en orden descendente
  arrange(desc(lifeExp)) %>%
  head(5)

```

Esto es fenomenal, pero si tomamos a todos los países en cualquier momento no tenemos una fotografía muy clara de los hechos. Quizás convendría mejor analizar los datos únicamente centrándonos en un año. Podemos filtrar los valores solo para el año 2007 con `filter()` y luego conectarlo con `arrange()` y `desc()` para ordenarlo de mayor a menor. Para concatenar acciones solo debemos conectarlas con el pipe operator (`%>%`)

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>%
  # Filtramos las filas donde year sea igual a 2007
  filter(year == 2007) %>%
  # Ordenamos las filas por la columna lifeExp en orden descendente
  arrange(desc(lifeExp)) %>%
  head(5)

```

**Mutate()**

Usamos la función `mutate()` para modificar columna existentes o crear nuevas.

![](images/clipboard-1384461819.png)

Crear una nueva columna con el Producto Interno Bruto (PIB)

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>%
  # Creamos una nueva columna llamada PIB_Bruto calculando gdpPercap * pop
  mutate(PIB_Bruto = gdpPercap * pop) %>%
  head(5)
```

Crear una nueva columna con el PIB en miles de millones:

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>%
  # Creamos una nueva columna llamada PBI_Mil_Millones 
  # dividiendo el PIB bruto entre mil millones
  mutate(PBI_Mil_Millones = 
           (gdpPercap * pop) / 1000000000) %>%
  head(5)
```

También podemos utilizar `mutate()` para modificar una variable existente, sobreescribiéndola. Supongamos que queremos aumentar en un 10% el PBI per cápita de todos los países.

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>%
  # Modificamos la columna gdpPercap aumentando su valor en un 10%
  mutate(gdpPercap = gdpPercap * 1.1) %>%
  head(5)
```

```{r}
head(gapminder %>%
       mutate(PBI_Mil_Millones = (gdpPercap * pop)/1000000000)
  
)
```

Finalmente, podemos concatenarlo con el resto de operaciones de la misa forma.

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>%
  # Seleccionamos solo las columnas de interés
  select(country, year, pop, gdpPercap) %>%
  # Filtramos las filas donde year sea igual a 2007
  filter(year == 2007) %>%
  # Ordenamos las filas por la columna gdpPercap en orden descendente
  arrange(desc(gdpPercap)) %>%
  # Creamos una nueva columna llamada PBI calculando gdpPercap * pop
  mutate(PBI = (gdpPercap * pop)) %>%
  # Mostramos las primeras 5 filas para facilitar la visualización
  head(5)
```

**Summarise() / Reframe()**

Cuando queremos obtener estadísticas resumidas de una o más variables (por ejemplo, calcular promedios, totales o conteos) usamos funciones como `summarise()`. Esta nos permite condensar la información y obtener un nuevo dataframe con solo los valores que nos interesan. En versiones recientes de dplyr, te va a aparecer `reframe()` en su lugar: esto se debe a que el paquete está actualizando algunos nombres para que reflejen mejor lo que hacen. No te preocupes, lo esencial es lo siguiente: usa `summarise()` si quieres un resumen compacto, y `reframe()` si necesitas conservar más de una fila por grupo o mayor flexibilidad.

![](images/clipboard-4262009664.png)

Supongamos que queremos conocer la esperanza de vida media.

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>%
  # Calculamos la esperanza de vida media
  summarise(espvida_media = mean(lifeExp))
```

Podemos calcular dos cosas a la vez. La esperanza de vida media y el total de la población

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>%
  # Calculamos la esperanza de vida media y el total de la población
  reframe(espvida_media = mean(lifeExp), popTotal = sum(pop))
```

Intentemos esta vez calcular la esperanza de vida media y el total de la población en América en 2002.

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>%
  # Filtramos las filas donde year sea igual a 2002
  # y el continente sea "Americas"
  filter(year == 2002, continent == "Americas") %>%
  # Calculamos la esperanza de vida media y el total de la población
  reframe(espvida_media = mean(lifeExp), popTotal = sum(pop))
```

Sin embargo, el verdadero poder de `reframe()` es cuando lo combinamos con la siguiente función.

**Group_by()**

Supongamos que queremos calcular la esperanza de vida y el total de la población de todos los países cada año. Para ello podríamos realizar el siguiente código

```{r}
# Empezando por el primer año...
gapminder %>%
  filter(year == 1952) %>%
  summarize(espvida_media = mean(lifeExp), popTotal = sum(pop))
```

Lo tenemos para un año, pero si quisiéramos aplicarlo para **cada año** esto sería bastante tedioso y quereriría muchas líneas de código, sin contar con que el resultado estará en dataframes separados. Para esto la función `group_by()` entra en acción.

La función `group_by` le dice a dplyr que realice las operaciones por grupos en vez de aplicarlas a todo el datset a la vez.

![](images/clipboard-3380744810.png)

Para ello simplemente tenemos que especificar la variable a agrupar, en este caso, los años.

```{r}
# Tomamos el conjunto de datos gapminder
gapminder %>%
  # Agrupamos los datos por la variable year
  group_by(year) %>%
  # Calculamos la esperanza de vida media y el total de la población por año
  summarise(espvida_media = mean(lifeExp), popTotal = sum(pop))
```

Y listo! El nuevo `data.frame` ahora muestra los datos para cada año en que se tomaron los datos.

### Dplyr en acción

Ahora que hemos aprendido las funciones básicas de `dplyr`, vamos a ponerlas en práctica con ejemplos concretos.

**Calcular la esperanza de vida media y el total de población de cada continente en el 2007, ordenado por mayor esperanza de vida**

Podemos filtrar los datos para el año 2007, agruparlos por continente, calcular la esperanza de vida media y el total de población, y luego ordenar los resultados por esperanza de vida media en orden descendente.

```{r}
gapminder %>%
# Filtramos los datos para el año 2007
  filter(year == 2007) %>%  
# Agrupamos los datos por continente
  group_by(continent) %>% 
# Calculamos la esperanza de vida media y el total de población
  summarise(espvida_media = mean(lifeExp), popTotal = sum(pop)) %>%  
# Ordenamos los resultados por esperanza de vida media en orden descendente
  arrange(desc(espvida_media))  
```

**Crear una nueva columna con el PIB total (PIB per cápita \* población) y filtrar los países con un PIB total mayor a 1 billón en 2007**

Vamos a crear una nueva columna para el PIB total, filtrar los datos para el año 2007, y luego seleccionar solo los países con un PIB total mayor a 1 billón.

```{r}
gapminder %>%
# Creamos una nueva columna para el PIB total
  mutate(PIB_Total = gdpPercap * pop) %>% 
# Filtramos los datos para el año 2007 y PIB total mayor a 1 billón
  filter(year == 2007, PIB_Total > 1e12) %>% 
# Seleccionamos las columnas de interés
  select(country, continent, PIB_Total) %>%  
# Ordenamos los resultados por PIB total en orden descendente
  arrange(desc(PIB_Total))  
```

**Calcular la esperanza de vida media y el total de población de cada continente a lo largo del tiempo**

En este ejemplo, queremos ver cómo ha cambiado la esperanza de vida media y la población total en cada continente a lo largo del tiempo.

```{r}
# Creamos 'x'
x = gapminder %>% 
# Agrupamos los datos por continente y año
  group_by(continent, year) %>% 
# Calculamos la esperanza de vida media y el total de población
  summarise(espvida_media = mean(lifeExp), popTotal = sum(pop)) %>% 
# Ordenamos los resultados por continente y año
  arrange(continent, year)  
# Seleccionamos únicamente los primeros 12 (África) por motivos estéticos
head(x, 12) 
```

**Comparar la esperanza de vida y el PIB per cápita entre dos países específicos (Perú y Chile) en 2007**

Vamos a filtrar los datos para los países Perú y Chile en el año 2007, y comparar la esperanza de vida y el PIB per cápita entre ellos.

```{r}
gapminder %>%
# Filtramos los datos para Perú y Chile en el año 2007
  filter(year == 2007, country %in% c("Peru", "Chile")) %>%
# Seleccionamos las columnas de interés
  select(country, lifeExp, gdpPercap) %>%  
# Ordenamos los resultados por país
  arrange(country)  
```

**Crear una nueva columna con la relación PIB per cápita y esperanza de vida, y analizar esta relación para los países en Asia en 2007**

Podemos crear una nueva columna para la relación entre PIB per cápita y esperanza de vida, y luego analizamos esta relación para los países en Asia en 2007.

```{r}
x = gapminder %>%
# Filtramos los datos para los países en Asia en 2007
  filter(year == 2007, continent == "Asia") %>%
# Creamos una nueva columna para la relación PIB per cápita / esperanza de vida
  mutate(PIB_vs_vida = gdpPercap / lifeExp) %>% 
# Seleccionamos las columnas de interés
  select(country, PIB_vs_vida) %>% 
# Ordenamos los resultados por la relación PIB per cápita / esperanza de vida en orden descendente
  arrange(desc(PIB_vs_vida))  

head(x, 10)
```

## Visualización

La última etapa del flujo de trabajo es la **visualización de datos**. Poder visualizar la información no solo nos ayuda a a anticipar ciertos patrones y comportamientos, sino que también facilita la comunicación de estos hallazgos a otros. Es importante reconocer que tendemos a dejarnos llevar más por los gráficos que por los resúmenes numéricos, aunque ambos sean igualmente importantes.

`ggplot2` es uno de los paquetes más populares y poderosos en R para la creación de gráficos. Para generar gráficos adecuados en R, necesitamos considerar dos elementos fundamentales: el elemento estadístico y el elemento de diseño. La finalidad de un gráfico es resumir y transmitir información de manera adecuada para el análisis que estamos realizando, sin olvidar la importancia de un diseño atractivo. `ggplot2` [@ggplot2] consigue ambos objetivos.

Antes de empezar a usar `ggplot2`, necesitamos instalarlo y cargarlo. de R.

```{r}
# Instalación del paquete ggplot2 (en caso no esté instalado)
#install.packages('ggplot2')

# Carga del paquete ggplot2
library(ggplot2)
```

### Fundamentos de ggplot2

La creación de gráficos con `ggplot2` se basa en la gramática de los gráficos (Grammar of Graphics). Esta gramática define una serie de componentes que forman parte de un gráfico:

1.  **Datos**: El conjunto de datos que queremos visualizar.
2.  **Estética**: La asignación de variables a aspectos visuales del gráfico, como posición, color, tamaño, etc.
3.  **Geometría**: El tipo de gráfico (barras, puntos, líneas, etc.).
4.  **Facetas**: Subdivisiones del gráfico en múltiples paneles basados en una o más variables.
5.  **Estadísticas**: Transformaciones estadísticas que se aplican a los datos antes de graficarlos.
6.  **Coordenadas**: El sistema de coordenadas usado (cartesiano, polar, etc.).
7.  **Tema**: Elementos de diseño y formato del gráfico.

Piensa en cada uno de ellos como una capa que va encima. Para construir un gráfico en `ggplot2`, concatenamos diferentes capas usando el operador `+`. Cada capa añade un nuevo componente al gráfico.

![Extraído de: https://cristoichkov.github.io](images/clipboard-1644515835.png)

Vamos a empezar con un gráfico de dispersión básico utilizando el conjunto de datos `gapminder`. Este conjunto contiene datos sobre el Producto Interno Bruto (PIB) per cápita, la esperanza de vida y otros indicadores para varios países a lo largo del tiempo.

Empezamos agregando la primera capa, los datos. Para comenzar, creamos la base del gráfico con la función `ggplot()`, y como argumento el conjunto de datos `gapminder`.

```{r}
ggplot(gapminder)
```

Como ves, los datos por si solos únicamente nos dan un recuadro blanco, debemos añadir el resto de capas. Definimos las estéticas del gráfico con la función `aes()`, asignando el PIB per cápita al eje x (`gdpPercap`) y la esperanza de vida al eje y (`lifeExp`).

```{r}
ggplot(gapminder, aes(x = gdpPercap, y = lifeExp))
```

Ahora que R sabe qué datos vamos a utilizar y qué variables tomar como coordenadas, necesitamos especificar qué tipo de gráfico queremos crear. En `ggplot2`, hay muchas `geoms` (geometrías), y cada una proporciona un tipo de gráfico diferente. Por ejemplo, `geom_bar` crea un gráfico de barras y `geom_line` crea un gráfico de líneas. En este caso, como ambas variables (PIB per cápita y esperanza de vida) son numéricas, usaremos un gráfico de dispersión (puntos) para visualizar la relación entre ellas. Para ello, usamos `geom_point()`.

```{r}
ggplot(gapminder, aes(x = gdpPercap, y = lifeExp)) +
  geom_point()
```

En este ejemplo, `aes(x = gdpPercap, y = lifeExp)` define la estética del gráfico, asignando el Producto Interno Bruto per cápita al eje x y la esperanza de vida al eje y. `geom_point()` especifica que queremos un gráfico de dispersión. Ya puedes lanzarte a sacar tus primeras conclusiones.

Algo que podemos notar es que el gráfico se ve un poco apretado al principio. Para mejorar la visualización, podemos usar una escala logarítmica en el eje x. Esto transforma los datos para que las diferencias entre los puntos se aprecien mejor, especialmente cuando algunos países tienen un PIB per cápita muy alto y otros muy bajo. Solo recuerda que usar una escala logarítmica cambia la manera en que interpretamos el gráfico, así que debemos tenerlo en cuenta.

Usamos `scale_x_log10()` para transformar el eje x a una escala logarítmica.

```{r}
ggplot(gapminder, aes(x = gdpPercap, y = lifeExp)) +
  geom_point() +
  scale_x_log10()
```

En este caso, hemos añadido `scale_x_log10()` para aplicar la escala logarítmica en el eje x. Esto clarifica la relación entre las variables, permitiéndonos observar que un mayor PIB per cápita generalmente se asocia con una mayor esperanza de vida.

También podemos añadir otros elementos estéticos para mejorar la visualización, como el color de los puntos basado en el continente. Para ello, modificamos `aes()` para incluir `color = continent`, lo que añade color a los puntos según el continente. Recuerda que `continent` es una variable categórica del conjunto de datos.

```{r}
ggplot(gapminder, aes(x = gdpPercap, 
                      y = lifeExp, 
                      color = continent)) +
  geom_point() +
  scale_x_log10()
```

Te animo a que sigas intentando identificar patrones importantes. Por ejemplo, ¿dónde se encuentran los puntos asociados a determinados continentes? ¿Existe alguna relación entre el continente y las otras dos variables?

Este gráfico ya es de por si sumamente útil pero si deseamos poder comunicarlo cada uno de los elementos deben estar debidamente nombrados. Para ello, es importante añadir etiquetas y títulos para mejorar la interpretación del gráfico. Esto lo podemos hacer agregando una capa más con la función `labs()` y usando como argumentos `title`, `x`, `y` y `color`.

Usamos `labs()` para añadir un título y etiquetas a los ejes.

```{r}
ggplot(gapminder, aes(x = gdpPercap, y = lifeExp, color = continent)) +
  geom_point() +
  scale_x_log10() +
  labs(title = "Relación entre PIB per cápita y Esperanza de Vida",
          x = "PIB per cápita (log10)",
          y = "Esperanza de Vida",
          color = "Continente")
```

Otra capa opcional que también podemos agregar es el `facet`. El facetado permite dividir el gráfico en múltiples paneles basados en una o más variables. Por ejemplo, podemos crear un gráfico separado para cada continente.

Usamos `facet_wrap(~ continent)` para dividir el gráfico en múltiples paneles, uno para cada continente.

```{r}
ggplot(gapminder, aes(x = gdpPercap, y = lifeExp, color = continent)) +
  geom_point() +
  scale_x_log10() +
  labs(title = "Relación entre PIB per cápita y Esperanza de Vida",
      x = "PIB per cápita (log10)",
      y = "Esperanza de Vida",
      color = "Continente") +
  facet_wrap(~ continent) +
# Puedes quitar la leyenda con esta capa adicional
  theme(legend.position = "none")

```

Tenemos la última capa, los themes. La capa de themes tiene una multitud de funciones que permiten modificar de forma precisa el tamaño, posición o forma de casi todos los elementos del gráfico. Por ejemplo, en el gráfico anterior eliminamos la leyenda usando un theme. Los themes permiten personalizar la apariencia del gráfico de manera detallada.Esta guía no tiene como objetivo explorar la complejidad de los themes en profundidad, así que nos centraremos en los themes predeterminados.

¿Recuerdas el gráfico que generamos antes de los facets? Vamos a volver a utilizarlo para ejemplificar los diversos temas en ggplot.

```{r}
ggplot(gapminder, aes(x = gdpPercap, y = lifeExp, color = continent)) +
  geom_point() +
  scale_x_log10() +
  labs(title = "Relación entre PIB per cápita y Esperanza de Vida",
          x = "PIB per cápita (log10)",
          y = "Esperanza de Vida",
          color = "Continente")
```

Pero no tenemos que volver a escribirlo. Verás, los gráficos también son un tipo de objeto en R así que puedes ser almacenarlos en forma de una variable. De esta forma:

```{r}
grafico = ggplot(gapminder, aes(x = gdpPercap, y = lifeExp, color = continent)) +
  geom_point() +
  scale_x_log10() +
  labs(title = "Relación entre PIB per cápita y Esperanza de Vida",
          x = "PIB per cápita (log10)",
          y = "Esperanza de Vida",
          color = "Continente")
```

Ahora solo basta con llamarlo por su recien adquirido nombre

```{r}
grafico
```

Como decíamos, existen varios themes predeterminados en ggplot2. Los themes en `ggplot2` permiten personalizar la apariencia de los gráficos de manera detallada. Existen varios themes predeterminados que se pueden usar para cambiar el aspecto de los gráficos sin necesidad de realizar configuraciones complejas.

Ya que nombramos al objeto gráfico, podemos añadir una capa fácilmente con el signo `+`

El `theme_minimal` es un tema limpio y sencillo, con un fondo blanco y líneas de cuadrícula ligeras.

```{r}
grafico + theme_minimal()
```

El `theme_gray` es el tema predeterminado en `ggplot2`, con un fondo gris claro y líneas de cuadrícula blancas.

```{r}
grafico + theme_gray()
```

El `theme_bw` es similar al `theme_gray`, pero utiliza un fondo blanco y es útil para presentaciones en blanco y negro.

```{r}
grafico + theme_bw()
```

El `theme_classic` se asemeja los gráficos clásicos de R base, con un fondo blanco y ejes negros.

```{r}
grafico + theme_classic()
```

El `theme_void` elimina todos los elementos no esenciales del gráfico, dejando solo los datos. Es útil para gráficos personalizados donde se desea agregar y tener control de cada cosa de forma manual.

```{r}
grafico + theme_void()
```

El `theme_dark` utiliza un fondo oscuro con líneas de cuadrícula claras.

```{r}
grafico + theme_dark()
```

Cada uno de estos themes puede ser modificado y combinado con otros elementos para crear gráficos personalizados según las necesidades específicas del análisis. En particular, utilizaré el theme_minimal por preferencia personal. Pero recuerdas que puedes utilizar el que se adapte mejor a tus necesidades.

### Tipos de gráficos

Así como existen diferentes tipos de variables, también hay diversos gráficos que se pueden utilizar para representarlas adecuadamente. A continuación, se presentan algunos de los gráficos más importantes y que se utilizarán en los próximos capítulos.

**Gráfico de barras**

Un gráfico de barras es útil para visualizar la frecuencia de categorías o la comparación de cantidades entre diferentes categorías.

Para crear un gráfico de barras en R, podemos usar la función `geom_bar()`. Si solo queremos contar las observaciones en una sola variable, podemos usar `geom_bar()` sin especificar ambos ejes:

```{r}
# Cuenta simple
ggplot(gapminder, aes(x = continent, fill = continent)) +
  geom_bar() +
  labs(
    title = "Frecuencia de países por continente",
    x = "Continente",
    y = "Frecuencia"
  ) +
  theme_minimal()
```

En este caso, el argumento `fill` se utiliza para rellenar las barras con colores diferentes según la categoría (en este caso, el continente). La diferencia entre `fill` y `color` es que `fill` se utiliza para rellenar el interior de las formas (como barras o áreas), mientras que `color` se usa para definir el color de los bordes de las formas.

Pero cuando queremos especificar ambos ejes, como cuando estamos comparando cantidades específicas entre categorías, usamos `geom_col` y especificamos ambos ejes en `aes`:

Por ejemplo, vamos a contar el número de países en cada continente que tienen una esperanza de vida mayor a 75 años en el año 2007.

Primero preparamos los datos con `dplyr`, filtrando los datos para el año 2007 y luego contando los países por continente con una esperanza de vida mayor a 75 años.

```{r}
datos <- gapminder %>%
  filter(year == 2007, lifeExp > 75) %>%
  group_by(continent) %>%
  summarise(
    n = n_distinct(country)  # Contar el número de países únicos
  )
```

Aquí tenemos los datos preparados:

```{r}
datos
```

Luego, creamos el gráfico de barras especificando ambas coordenadas con `geom_col()`:

```{r}
# Podemos usar la función reorder() para ordenar de mayor a menor en el gráfico
ggplot(datos, aes(x = reorder(continent, n), y = n, fill = continent)) +
  geom_col() +
  labs(title = "Países con esperanza de vida mayor a 75 años en 2007",
       x = "Continente",
       y = "Número de Países",
       fill = "Continente") +
  theme_minimal()
```

Podemos invertir fácilmente el gráfico usando `coord_flip()`:

```{r}
ggplot(datos, aes(x = reorder(continent, n), y = n, fill = continent)) +
  geom_col() +
  labs(title = "Países con esperanza de vida mayor a 75 años en 2007",
       x = "Continente",
       y = "Número de Países",
       fill = "Continente") +
  theme_minimal() +
  coord_flip()
```

**Histograma**

Un histograma es útil para visualizar la distribución de una variable numérica. Muestra la frecuencia de valores en intervalos específicos.

Para crear un histograma en R, usamos la función `geom_histogram()`:

```{r}
ggplot(gapminder, aes(x = lifeExp)) +
  geom_histogram(binwidth = 5, fill = "blue", color = "black") +
  labs(title = "Distribución de la esperanza de vida",
       x = "Esperanza de vida",
       y = "Frecuencia") +
  theme_minimal()
```

**Gráfico de líneas**

Un gráfico de líneas es útil para visualizar la tendencia de una variable a lo largo del tiempo.

Para preparar los datos, calculamos la esperanza de vida media por año:

```{r}
gapminder %>%
  group_by(year) %>%
  summarise(lifeExp_mean = mean(lifeExp))
```

Otra ventaja de usar `dplyr` y `ggplot` juntos es que podemos unir ambos códigos con un pipe operator. Usamos `geom_line(color = "blue")` para crear el gráfico de líneas:

```{r}
gapminder %>%
  group_by(year) %>%
  summarise(lifeExp_mean = mean(lifeExp)) %>%
  ggplot(aes(x = year, y = lifeExp_mean)) +
      geom_line(color = "blue") +
  labs(title = "Tendencia de la esperanza de vida media a lo largo del tiempo",
       x = "Año",
       y = "Esperanza de vida media") +
  theme_minimal()
```

**Boxplot**

Un boxplot es útil para visualizar la distribución de una variable y comparar distribuciones entre diferentes categorías. Hablaremos de él de forma mas rigurosa en el siguiente capítulo

Para crear el boxplot de la esperanza de vida por continente, usamos `geom_boxplot()`:

```{r}
ggplot(gapminder, aes(x = continent, y = lifeExp, fill = continent)) +
  geom_boxplot() +
  labs(title = "Distribución de la esperanza de vida por continente",
       x = "Continente",
       y = "Esperanza de vida") +
  theme_minimal() +
  theme(legend.position = "none")
```

Estos son algunos de los tipos de gráficos que utilizaremos para analizar datos en los próximos capítulos. Cada uno tiene su utilidad específica y pueden añadirse más detalles en función del objetivo que se tenga para la investigación.

## Flor y el análisis del bienestar social

Flor encontró un conjunto de datos abierto sobre **indicadores de bienestar social**, que incluía información reciente sobre ingresos, niveles educativos y acceso a servicios básicos en diversas regiones.

Flor descargó un archivo CSV y lo IMPORTÓ a R.

```{r}
library(readr)
bienestar = read_csv("datos_bienestar.csv")
```

Analiza la estructura de los datos

```{r}
glimpse(bienestar)
```

Al explorar los datos, encontró variables como:

-   `region`: La región de cada observación. - `ingreso_mensual`: El ingreso promedio mensual de cada hogar.

-   `nivel_educativo`: Nivel educativo mas alto alcanzado por la mayoría (Primaria, Secundaria, Superior).

-   `acceso_servicios`: Porcentaje de hogares con acceso a servicios básicos (agua y electricidad).

Primero, los nombres de las columnas no eran uniformes y contenían espacios que complicaban su manipulación. Decidió solucionar estos problemas antes de continuar.

```{r}
library(janitor)

bienestar = clean_names(bienestar)

colnames(bienestar)
```

Además, al revisar el conjunto de datos, Flor notó algunos **VALORES FALTANTES** en `ingreso_mensual`. Se dispone a comprobar.

```{r}
sum(is.na(bienestar$ingreso_mensual)) 
```

Tenemos 51 valores perdidos. En este caso en particular, tomó la decisión de eliminarlos.

```{r}
library(tidyr)
bienestar = drop_na(bienestar)
```

Flor decidió explorar las **diferencias en el ingreso promedio por región** y cómo estas se relacionaban con el nivel educativo y el acceso a servicios básicos. Para ello tuvo que MANIPULAR los datos usando **dplyr**.

```{r}
library(dplyr)
```

Calculó el ingreso promedio por región

```{r}
# Agrupa por región y calcula el ingreso promedio
ingreso_por_region = bienestar %>%
  group_by(region) %>%
  summarise(ingreso_promedio = mean(ingreso_mensual))

ingreso_por_region
```

Flor notó que algunas regiones tenían ingresos más altos. Esto la llevó a preguntarse si el acceso a servicios básicos podría explicar parte de estas diferencias.Flor creó una tabla que mostraba el ingreso promedio y el acceso promedio a servicios básicos por región.

```{r}
# Agrupam por región y calcula el ingreso promedio y acceso promedio
bienestar_region = bienestar %>%
  group_by(region) %>%
  summarise(
    ingreso_promedio = mean(ingreso_mensual),
    acceso_servicios_promedio = mean(acceso_a_servicios)
  )

bienestar_region
```

Una alternativa que planteó para simplificar la comparación fue clasificar los ingresos en "Altos" y "Bajos" según el promedio nacional. Para ello, integró la función `ifelse()` a su estructura de dplyr. `ifelse()` está estructurada para evaluar condiciones lógicas. En este caso, se escribe como `ifelse(ingreso_mensual > promedio_nacional, "Alto", "Bajo")`, donde la condición (`ingreso_mensual > promedio_nacional`) se evalúa para cada fila del vector. Si es verdadera (`TRUE`), se asigna el valor `"Alto"`, y si es falsa (`FALSE`), se asigna `"Bajo"`.

```{r}
# Calcula el ingreso promedio nacional
promedio_nacional = mean(bienestar$ingreso_mensual)

promedio_nacional
```

```{r}
# Crea una nueva columna con la clasificación de ingresos
bienestar = bienestar %>%
  mutate(
    categoria_ingreso = 
      ifelse(ingreso_mensual > promedio_nacional, # Condición
             "Alto",                              # Si la condición es verdadera
             "Bajo")                              # Si la condición es falsa
  )

head(bienestar, 10)
```

![Manipular datos es parte esencial de un análisis bien estrcuturado](images/Ilustración_sin_título%201.png){fig-align="center" width="453"}

Flor era consciente de que podía interpretar mejor sus resultados visualmente asi que decidió usar ggplot2 para crear VISUALIZACIONES.

```{r}
library(ggplot2)
```

Quería mostrar cómo variaba el ingreso promedio entre regiones. Usó `geom_col()` para crear un gráfico de barras.

```{r}
# Gráfico de barras del ingreso promedio por región
ggplot(ingreso_por_region, aes(x = reorder(region, ingreso_promedio), 
                               y = ingreso_promedio, 
                               fill = region)) +
  geom_col() +
  labs(
    title = "Ingreso Promedio por Región",
    x = "Región",
    y = "Ingreso Promedio"
  ) +
  coord_flip() +
  theme_minimal()
```

Luego, quería explorar la relación entre el ingreso y el acceso a servicios básicos.

```{r}
# Gráfico de dispersión por localidad
ggplot(bienestar, aes(x = acceso_a_servicios, 
                      y = ingreso_mensual, 
                      color = region)) +
 # Le puso puntos con transparencia para mejor visualización
   geom_point(size = 3, alpha = 0.7) +  
  labs(
    title = "Relación entre Acceso a Servicios Básicos e Ingreso por Localidad",
    x = "Acceso a Servicios Básicos (%)",
    y = "Ingreso Mensual",
    color = "Región"
  ) +
  theme_minimal()
```

Finalmente, Flor decidió analizar cómo variaba el ingreso por nivel educativo, usando facetas para separar cada región.

```{r}
# Gráfico de facetas
ggplot(bienestar, aes(x = nivel_educativo, 
                      y = ingreso_mensual, 
                      fill = nivel_educativo)) +
  geom_boxplot() +
  facet_wrap(~ region) +
  labs(
    title = "Ingreso Mensual por Nivel Educativo y Región",
    x = "Nivel Educativo",
    y = "Ingreso Mensual"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```

![Los gráficos nos ayudan a representar el comportamiento de nuestras variables y la relación entre ellas](images/Ilustración_sin_título%202.png){fig-align="center" width="444"}

## Resumen del capítulo

El análisis de datos en R se estructura como un flujo lógico que empieza con la importación de datos, continúa con su limpieza, exploración y transformación, y finaliza con visualizaciones claras. En este libro el flujo lo hemos ejecutado principalmente con herramientas del *tidyverse*, una colección de paquetes diseñados para ser compatibles entre sí y mantener una sintaxis consistente.

Los datos se trabajan sobre estructuras tabulares, como `data.frame` y `tibble`, que permiten manejar variables de distintos tipos. Para importar datos se utilizan funciones como `read_csv()` para archivos CSV, `read_excel()` para Excel y `read_dta()` o `read_sav()` para formatos de Stata y SPSS.

La limpieza de datos es crítica. Se identifican y eliminan valores faltantes con `is.na()` y `drop_na()`, se estandarizan nombres con `clean_names()` del paquete `janitor`, se eliminan duplicados con `distinct()` y se corrigen tipos de datos con `as.numeric()` o funciones equivalentes. La inspección estructural se apoya en funciones como `str()`, `glimpse()`, `summary()`, `head()` y `dim()`.

La transformación y manipulación se organiza mediante `dplyr`. Con `filter()` se filtran filas, `select()` permite aislar columnas, `mutate()` crea o modifica variables, `arrange()` ordena observaciones, `group_by()` agrupa por categorías, y `summarise()` / `reframe()` extrae estadísticas resumidas. El uso del operador `%>%` permite encadenar acciones una tras de otra.

Para visualizar se emplea `ggplot2`, que construye gráficos en capas a partir de una gramática declarativa. Se definen las estéticas con `aes()`, se elige la geometría adecuada (`geom_point()`, `geom_col()`, `geom_histogram()`, `geom_boxplot()`...), se pueden usar facetas con `facet_wrap()`, transformar escalas como con `scale_x_log10()` y ajustar diseño con `theme_minimal()` u otros temas prediseñados. Las visualizaciones se optimizan añadiendo títulos y etiquetas con `labs()` y organizando el gráfico en objetos que pueden modificarse sucesivamente.

## Ejercicios

**1. Tienes un archivo llamado `datos_bienestar.csv`. ¿Cuál es la forma correcta de cargarlo en R usando el paquete `readr`?**

a)  `read.csv("datos_bienestar.csv")`

b)  `read_csv("datos_bienestar.csv")`

c)  `library(readr)` seguido de `read_csv("datos_bienestar.csv")`

d)  `library(dplyr)` seguido de `read_csv("datos_bienestar.csv")`

**2. Después de importar los datos, Flor notó que los nombres de las columnas contenían espacios y caracteres especiales. ¿Qué paquete y función usó para estandarizar los nombres de las columnas?**

a)  `tidyr` y `drop_na()`

b)  `janitor` y `clean_names()`

c)  `dplyr` y `mutate()`

d)  `tibble` y `glimpse()`

**3. ¿Cómo puedes contar cuántos valores faltantes (`NA`) hay en la columna `ingreso_mensual` de un dataframe llamado `bienestar`?**

a)  `sum(bienestar$ingreso_mensual == NA)`

b)  `is.na(bienestar$ingreso_mensual)`

c)  `sum(is.na(bienestar$ingreso_mensual))`

d)  `measure(is.na(bienestar$ingreso_mensual))`

**4. Flor quiere trabajar únicamente con las filas donde la región sea "Norte". ¿Qué código es correcto para este propósito?**

a)  `filter(bienestar$region == "Norte")`

b)  `bienestar %>% filter(region == "Norte")`

c)  `bienestar %>% select(region == "Norte")`

d)  `bienestar %>% filter(region = "Norte")`

**5. Flor quiere crear una nueva columna llamada `acceso_clasificado` que clasifique el acceso a servicios básicos en "Alto" si es mayor al 70% y "Bajo" si no. ¿Qué código es correcto?**

a)  `mutate(acceso_clasificado = ifelse(acceso_servicios > 70, "Alto", "Bajo"))`

b)  `mutate(acceso_servicios = ifelse(acceso_servicios > 70, "Alto", "Bajo"))`

c)  `bienestar %>% mutate(acceso_clasificado = ifelse(acceso_servicios > 70, "Alto", "Bajo"))`

d)  `bienestar <- mutate(acceso_clasificado = ifelse(acceso_servicios > 70, "Alto", "Bajo"))`

**6. Flor quiere calcular el ingreso promedio por región. ¿Qué código es correcto?**

a)  `bienestar %>% summarize(region, mean(ingreso_mensual))`

b)  `group_by(bienestar$region) %>% summarize(mean(ingreso_mensual))`

c)  `bienestar %>% group_by(region) %>% summarize(ingreso_promedio = mean(ingreso_mensual))`

d)  `group_by(bienestar) %>% summarize(region, mean(ingreso_mensual))`

**7. Flor desea visualizar el ingreso promedio por región en un gráfico de barras. ¿Qué código es correcto?**

a)  

```         
ggplot(bienestar, aes(x = region, 
                      y = mean(ingreso_mensual))) +
  geom_col()
```

b)  

```         
ggplot(bienestar %>% 
         group_by(region) %>% 
         summarise(ingreso_promedio = mean(ingreso_mensual)),
       aes(x = region, 
           y = ingreso_promedio)) +
  geom_col()
```

c)  

```         
ggplot(bienestar %>% 
         group_by(region), 
       aes(x = region, 
           y = mean(ingreso_mensual))) +
  geom_bar()
```

d)  

```         
ggplot(bienestar, 
       aes(x = region, 
           y = ingreso_mensual)) +
  geom_bar(stat = "summary", 
           fun = "mean")
```

**8. Flor quiere crear un gráfico de dispersión para observar la relación entre el ingreso mensual y el acceso a servicios básicos, con puntos coloreados según la región. ¿Qué código es correcto?**

a)  

```         
ggplot(bienestar, 
       aes(x = acceso_servicios, 
           y = ingreso_mensual, 
           color = region)) +
  geom_point()
```

b)  

```         
ggplot(bienestar, 
       aes(x = ingreso_mensual, 
           y = acceso_servicios, 
           fill = region)) +
  geom_point()
```

c)  

```         
ggplot(bienestar, 
       aes(x = acceso_servicios, 
           y = ingreso_mensual)) +
  geom_point(color = region)
```

d)  

```         
ggplot(bienestar, aes(x = acceso_servicios, 
                      y = ingreso_mensual)) +
  geom_point(aes(color = region))
```

**9. Flor quiere analizar cómo varía el ingreso mensual según el nivel educativo en cada región. Usa facetas para separar por región. ¿Qué código es correcto?**

a)  

```         
ggplot(bienestar, aes(x = nivel_educativo, 
                      y = ingreso_mensual, 
                      fill = nivel_educativo)) +
  geom_boxplot() +
  facet_grid(~ region)
```

b)  

```         
ggplot(bienestar, aes(x = nivel_educativo, 
                      y = ingreso_mensual, 
                      fill = nivel_educativo)) +
  geom_boxplot() +
  facet_wrap(~ region)
```

c)  

```         
ggplot(bienestar, aes(x = ingreso_mensual, 
                      y = nivel_educativo, 
                      fill = region)) +
  geom_boxplot() +
  facet_wrap(~ region)
```

d)  

```         
ggplot(bienestar, aes(x = nivel_educativo, 
                      y = ingreso_mensual, 
                      fill = region)) +
  geom_boxplot() +
  facet_wrap(~ region)
```
